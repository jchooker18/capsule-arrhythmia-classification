# -*- coding: utf-8 -*-
"""Copy of capsule.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GHf6noE0yAD3ZeG1RhSx434D990wPoPi
"""

import numpy as np
np.random.seed(1)
from plots import loss_plot, accuracy_plot
import pickle
from collections import Counter
import tensorflow as tf
tf.random.set_seed(1)
import scipy.io as io
from sklearn.model_selection import train_test_split

"""Get data"""

labels_path = 'data/mitdb_label.npy'
# images_path = 'data/mitdb_images_np_28x28.npy'
# images_path = 'data/mitdb_images_np_60x60.npy'
images_path = 'data/mitdb_images_np_100x100.npy'


images = np.load(images_path, mmap_mode='r')
images = images / 255.

print('images loaded')

labels = np.load(labels_path)

print('labels loaded')

classes = ['N','L','R','V','/','A','F','f','j','a','E','J','e','Q','S']

# replace class characters with indices 
index = 0
for x in classes:
   for i in range(len(labels)):
       if labels[i] == x:
           labels[i] = index
   index = index +1


# Extracting top 6 classes for testing
index_top_classes = np.where(np.logical_and(labels>='0', labels<='5'))
images = images[index_top_classes]
labels = labels[index_top_classes]

# split into train and test sets, stratify on labels to make sure all classes represented in both
X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, stratify=labels) #, random_state=5

# add a channel dimension
X_train = np.expand_dims(X_train, axis=3)
X_test = np.expand_dims(X_test, axis=3)

y_train = y_train.astype('uint8')
y_test = y_test.astype('uint8')

del images
del labels

y_train_c = Counter(y_train)
y_test_c = Counter(y_test)

# separate class 0 from all other classes
y_train_class_0 = y_train[y_train == 0]
y_train_class_other = y_train[y_train != 0]
X_train_class_0 = X_train[y_train == 0]
X_train_class_other = X_train[y_train != 0]

y_test_class_0 = y_test[y_test == 0]
y_test_class_other = y_test[y_test != 0]
X_test_class_0 = X_test[y_test == 0]
X_test_class_other = X_test[y_test != 0]

# generate indices for undersampling
train_indices = np.random.randint(0, y_train_c[0], y_train_c[1])
test_indices = np.random.randint(0, y_test_c[0], y_test_c[1])

# perform undersampling
y_train_class_0_small = y_train_class_0[train_indices]
X_train_class_0_small = X_train_class_0[train_indices]

y_test_class_0_small = y_test_class_0[test_indices]
X_test_class_0_small = X_test_class_0[test_indices]

# add undersampled class 0 back to rest of classes
y_train = np.concatenate((y_train_class_0_small, y_train_class_other))
X_train = np.concatenate((X_train_class_0_small, X_train_class_other))

y_test = np.concatenate((y_test_class_0_small, y_test_class_other))
X_test = np.concatenate((X_test_class_0_small, X_test_class_other))

"""Capsule Model"""

#!/usr/bin/env python
# coding: utf-8

from tqdm import tqdm
from datetime import datetime
import ssl

# device_name = tf.test.gpu_device_name()
# if device_name != '/device:GPU:0':
#     raise SystemError('GPU device not found')
# print('Found GPU at: {}'.format(device_name))


# Parameters Based on Paper
epsilon = 1e-7
m_plus = 0.9
m_minus = 0.1
lambda_ = 0.5
alpha = 1e1
epochs = 2
no_of_secondary_capsules = 6

lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-4, decay_steps=1000,
    decay_rate=0.9)

optimizer = tf.keras.optimizers.Adam(lr_schedule)

params = {
    "no_of_conv_kernels": 128,
    "no_of_primary_capsules": 16,
    "no_of_secondary_capsules": 6,
    "primary_capsule_vector": 8,
    "secondary_capsule_vector": 16,
    "r":3,
}

pixels = X_train.shape[1] * X_train.shape[2]

testing_dataset_size = X_test.shape[0]
training_dataset_size = X_train.shape[0]

dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))
dataset = dataset.shuffle(buffer_size=len(dataset), reshuffle_each_iteration=True)
dataset = dataset.batch(batch_size=32)

testing = tf.data.Dataset.from_tensor_slices((X_test, y_test))
testing = testing.batch(batch_size=32)

class CapsuleNetwork(tf.keras.Model):
    def __init__(self, no_of_conv_kernels, no_of_primary_capsules, primary_capsule_vector, no_of_secondary_capsules, secondary_capsule_vector, r, pixels):
        super(CapsuleNetwork, self).__init__()
        self.no_of_conv_kernels = no_of_conv_kernels
        self.no_of_primary_capsules = no_of_primary_capsules
        self.primary_capsule_vector = primary_capsule_vector
        self.no_of_secondary_capsules = no_of_secondary_capsules
        self.secondary_capsule_vector = secondary_capsule_vector
        self.r = r
        self.pixels = pixels

        with tf.name_scope("Variables") as scope:
            self.conv_resize = tf.keras.layers.Conv2D(1, [73,73], strides=[1,1], name='resize', activation=tf.keras.layers.LeakyReLU(alpha=0.3), input_shape=(100, 100, 1), kernel_initializer='glorot_normal', kernel_regularizer=tf.keras.regularizers.L2(0.3)) #100x100
            # self.conv_resize = tf.keras.layers.Conv2D(1, [33,33], strides=[1,1], name='resize', activation='relu', input_shape=(60, 60, 1)) #60x60
            self.convolution = tf.keras.layers.Conv2D(self.no_of_conv_kernels, [9,9], strides=[1,1], name='ConvolutionLayer', activation=tf.keras.layers.LeakyReLU(alpha=0.3), kernel_initializer='glorot_normal', kernel_regularizer=tf.keras.regularizers.L2(0.3))
            self.primary_capsule = tf.keras.layers.Conv2D(self.no_of_primary_capsules * self.primary_capsule_vector, [9,9], strides=[2,2], name="PrimaryCapsule", kernel_initializer='glorot_normal', kernel_regularizer=tf.keras.regularizers.L2(0.3))
            self.w = tf.Variable(tf.random_normal_initializer()(shape=[1, 576, self.no_of_secondary_capsules, self.secondary_capsule_vector, self.primary_capsule_vector]), dtype=tf.float32, name="PoseEstimation", trainable=True)
            self.dense_1 = tf.keras.layers.Dense(units = 512, activation=tf.keras.layers.LeakyReLU(alpha=0.3), kernel_initializer='glorot_normal', kernel_regularizer=tf.keras.regularizers.L2(0.3)) # maybe 1000?
            self.dense_2 = tf.keras.layers.Dense(units = 1024, activation=tf.keras.layers.LeakyReLU(alpha=0.3), kernel_initializer='glorot_normal', kernel_regularizer=tf.keras.regularizers.L2(0.3)) #2000 for 60x60, 5000? for 100x100
            self.dense_3 = tf.keras.layers.Dense(units = self.pixels, activation='sigmoid', dtype='float32')
        
    def build(self, input_shape):
        pass
        
    def squash(self, s):
        with tf.name_scope("SquashFunction") as scope:
            s_norm = tf.norm(s, axis=-1, keepdims=True)
            return tf.square(s_norm)/(1 + tf.square(s_norm)) * s/(s_norm + epsilon)
    
    @tf.function
    def call(self, inputs):
        input_x, y = inputs
        
        input_x = self.conv_resize(input_x)
        x = self.convolution(input_x)
        x = self.primary_capsule(x)
        
        with tf.name_scope("CapsuleFormation") as scope:
            u = tf.reshape(x, (-1, self.no_of_primary_capsules * x.shape[1] * x.shape[2], 8))
            u = tf.expand_dims(u, axis=-2)
            u = tf.expand_dims(u, axis=-1)
            u_hat = tf.matmul(self.w, u)
            u_hat = tf.squeeze(u_hat, [4])

        
        with tf.name_scope("DynamicRouting") as scope:
            b = tf.zeros((input_x.shape[0], 576, self.no_of_secondary_capsules, 1)) # b.shape: (None, 1152, 10, 1)
            for i in range(self.r): # self.r = 3
                c = tf.nn.softmax(b, axis=-2) # c.shape: (None, 1152, 10, 1)
                s = tf.reduce_sum(tf.multiply(c, u_hat), axis=1, keepdims=True) # s.shape: (None, 1, 10, 16)
                v = self.squash(s) # v.shape: (None, 1, 10, 16)
                agreement = tf.squeeze(tf.matmul(tf.expand_dims(u_hat, axis=-1), tf.expand_dims(v, axis=-1), transpose_a=True), [4])
                b += agreement
                
        with tf.name_scope("Masking") as scope:
            y = tf.expand_dims(y, axis=-1)
            y = tf.expand_dims(y, axis=1)
            mask = tf.cast(y, dtype=tf.float32)
            v_masked = tf.multiply(mask, v)

        with tf.name_scope("Reconstruction") as scope:
            v_ = tf.reshape(v_masked, [-1, self.no_of_secondary_capsules * self.secondary_capsule_vector])
            reconstructed_image = self.dense_1(v_)
            reconstructed_image = self.dense_2(reconstructed_image)
            reconstructed_image = self.dense_3(reconstructed_image)
        
        return v, reconstructed_image

    @tf.function
    def predict_capsule_output(self, inputs):
        inputs = self.conv_resize(inputs)
        x = self.convolution(inputs)
        x = self.primary_capsule(x)
        
        with tf.name_scope("CapsuleFormation") as scope:
            u = tf.reshape(x, (-1, self.no_of_primary_capsules * x.shape[1] * x.shape[2], 8))
            u = tf.expand_dims(u, axis=-2)
            u = tf.expand_dims(u, axis=-1)
            u_hat = tf.matmul(self.w, u)
            u_hat = tf.squeeze(u_hat, [4])

        
        with tf.name_scope("DynamicRouting") as scope:
            b = tf.zeros((inputs.shape[0], 576, self.no_of_secondary_capsules, 1))
            for i in range(self.r):
                c = tf.nn.softmax(b, axis=-2)
                s = tf.reduce_sum(tf.multiply(c, u_hat), axis=1, keepdims=True)
                v = self.squash(s)
                agreement = tf.squeeze(tf.matmul(tf.expand_dims(u_hat, axis=-1), tf.expand_dims(v, axis=-1), transpose_a=True), [4])
                b += agreement
        return v

    @tf.function
    def regenerate_image(self, inputs):
        with tf.name_scope("Reconstruction") as scope:
            v_ = tf.reshape(inputs, [-1, self.no_of_secondary_capsules * self.secondary_capsule_vector])
            reconstructed_image = self.dense_1(v_)
            reconstructed_image = self.dense_2(reconstructed_image)
            reconstructed_image = self.dense_3(reconstructed_image)
        return reconstructed_image


model = CapsuleNetwork(**params, pixels=pixels)

@tf.function
def safe_norm(v, axis=-1, epsilon=1e-7):
    v_ = tf.reduce_sum(tf.square(v), axis = axis, keepdims=True)
    return tf.sqrt(v_ + epsilon)


@tf.function
def loss_function(v, reconstructed_image, y, y_image):
    prediction = safe_norm(v)
    prediction = tf.reshape(prediction, [-1, no_of_secondary_capsules])
    
    left_margin = tf.square(tf.maximum(0.0, m_plus - prediction))
    right_margin = tf.square(tf.maximum(0.0, prediction - m_minus))
    
    l = tf.add(y * left_margin, lambda_ * (1.0 - y) * right_margin)
    
    margin_loss = tf.reduce_mean(tf.reduce_sum(l, axis=-1))
    
    y_image_flat = tf.reshape(y_image, [-1, pixels])
    reconstruction_loss = tf.reduce_mean(tf.square(y_image_flat - reconstructed_image))
    
    loss = tf.add(margin_loss, alpha * reconstruction_loss)
    
    return loss

@tf.function
def train(x,y):
    y_one_hot = tf.one_hot(y, depth=6)
    with tf.GradientTape() as tape:
        v, reconstructed_image = model([x, y_one_hot])
        loss = loss_function(v, reconstructed_image, y_one_hot, x)
    grad = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(grad, model.trainable_variables))
    return loss

_ = train(X_train[:32],y_train[:32])

model.summary()

# @tf.function
def predict(model, x):
    pred = safe_norm(model.predict_capsule_output(x))
    pred = tf.squeeze(pred, [1])
    return np.argmax(pred, axis=1)[:,0]

epoch_loss = []
epoch_accuracy = []
batch_losses = []
batch_accuracy = []

for i in range(1, epochs+1, 1):

    loss = 0
    training_sum = 0
    mean_batch_loss = 0
    with tqdm(total=len(dataset)) as pbar:
        
        description = "Epoch " + str(i) + "/" + str(epochs)
        pbar.set_description_str(description)

        for X_batch, y_batch in dataset:
            loss += train(X_batch,y_batch)
            pbar.update(1)

            loss /= len(dataset)
            batch_losses.append(loss.numpy())

            y_pred = predict(model, X_batch)
            # y_preds_train.append(y_pred)
            training_sum = sum(y_pred==y_batch.numpy())
            batch_accuracy. append(training_sum/X_batch.shape[0])
            print('\r',"Loss :" + str(loss.numpy()) + " Batch Accuracy :" + str(training_sum/X_batch.shape[0]),end='')

        loss_plot(batch_losses, 'Loss_per_Batch')
        accuracy_plot(batch_accuracy, 'Train_accuracy_per_batch')

    epoch_loss.append(batch_losses)
    epoch_accuracy.append(batch_accuracy)


test_sum = 0
y_preds_test = []
test_accuracy = []
for X_batch, y_batch in testing:
    y_pred = predict(model, X_batch)
    y_preds_test.append(y_pred)
    test_sum = sum(y_pred==y_batch.numpy())
    print( '\r' 'Test accuracy {0}' .format(test_sum/testing_dataset_size),end='')
    test_accuracy.append(test_sum/testing_dataset_size)

test_dict_export = {'test_data': y_batch, 'test_pred': y_preds_test, 'test_accuracy':test_accuracy, 'epoch_loss': epoch_loss, 'epoch_accuracy': epoch_accuracy}
io.savemat('loss_accuracy_logs_Test3.mat',test_dict_export)
accuracy_plot(test_accuracy, 'Test_accuracy')